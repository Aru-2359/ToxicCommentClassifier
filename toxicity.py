# -*- coding: utf-8 -*-
"""Toxicity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MQYTNFqxOY_qpN6cC7SFg0Qyr0GfXynp
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install tensorflow pandas matplotlib scikit-learn gradio

import os
import pandas as pd
import tensorflow as tf
import numpy as np

#df = pd.read_csv(os.path.join('jigsaw-toxic-comment-classification-challenge','train.csv', 'train.csv'))

df = pd.read_csv('train.csv')

df[df['toxic']==1].head(10)

df.tail()

df.iloc[55]['comment_text']

df[df.columns[2:]].iloc[55]

from tensorflow.keras.layers import TextVectorization

df.columns

df[df.columns[2:]].values

X = df['comment_text']
Y = df[df.columns[2:]].values

X

Y

MAX_FEATURES =200000

vectorizer = TextVectorization(max_tokens=MAX_FEATURES, output_sequence_length=1800, output_mode='int')

X.values

type(X.values)

vectorizer.adapt(X.values)

vectorizer.get_vocabulary()

vectorized_text = vectorizer(X.values)

vectorized_text

dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, Y))
dataset = dataset.cache()
dataset = dataset.shuffle(160000)
dataset = dataset.batch(16)
dataset = dataset.prefetch(8)

batch_X, batch_Y = dataset.as_numpy_iterator().next()

train = dataset.take(int(len(dataset)*.7))
val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))
test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))

train_generator = train.as_numpy_iterator()

train_generator.next()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding

model = Sequential()
model.add(Embedding(MAX_FEATURES+1, 32))
model.add(Bidirectional(LSTM(32, activation='tanh')))
model.add(Dense(128, activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(6, activation='sigmoid'))

model.compile(loss= 'BinaryCrossentropy', optimizer='Adam')

model.summary()

history = model.fit(train, epochs=5, validation_data=val)

from matplotlib import pyplot as plt

plt.figure(figsize=(8, 5))
pd.DataFrame(history.history).plot()
plt.show()

input_text = vectorizer(np.array(['You freaking suck! I am going to hit you.']))

input_text

res = model.predict(input_text)

(res > 0.5).astype(int)

batch_X, batch_y = test.as_numpy_iterator().next()

(model.predict(batch_X) > 0.5).astype(int)

res.shape

from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy

pre = Precision()
re = Recall()
acc = CategoricalAccuracy()

for batch in test.as_numpy_iterator():
    X_true, y_true = batch
    yhat = model.predict(X_true)

    y_true = y_true.flatten()
    yhat = yhat.flatten()

    pre.update_state(y_true, yhat)
    re.update_state(y_true, yhat)
    acc.update_state(y_true, yhat)

print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')

# Commented out IPython magic to ensure Python compatibility.
# %pip install gradio jinja2

# Commented out IPython magic to ensure Python compatibility.
# %pip show gradio

import tensorflow as tf
import gradio as gr

model.save('toxicity.h5')

model = tf.keras.models.load_model('toxicity.h5')

input_str = vectorizer('hey i freaken hate you!')
res = model.predict(np.expand_dims(input_str,0))

res

def score_comment(comment):
    vectorized_comment = vectorizer([comment])
    results = model.predict(vectorized_comment)

    text = ''
    for idx, col in enumerate(df.columns[2:]):
        text += '{}: {}\n'.format(col, results[0][idx]>0.5)

    return text

# Commented out IPython magic to ensure Python compatibility.
# %pip install --upgrade gradio

import gradio as gr

interface = gr.Interface(
    fn=score_comment,
    inputs=gr.Textbox(lines=2, placeholder='Comment to score'),
    outputs='text'
)

interface.launch(share=True)

